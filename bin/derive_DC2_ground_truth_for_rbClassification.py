#!/usr/bin/env python
# coding: utf-8

# Import required libraries and modules
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from tqdm import tqdm

# Define file paths.
star_sum_path = '/sdf/data/rubin/shared/dc2_run2.2i_truth/truth_star/truth_star_summary_v1-0-0.parquet'
star_var_path = '/sdf/data/rubin/shared/dc2_run2.2i_truth/truth_star/truth_star_variability_v1-0-0.parquet'
sn_sum_path = '/sdf/data/rubin/shared/dc2_run2.2i_truth/truth_sn/truth_sn_summary_v1-0-0.parquet'
sn_var_path = '/sdf/data/rubin/shared/dc2_run2.2i_truth/truth_sn/truth_sn_variability_v1-0-0.parquet'
# This is the CSV generated by the plotImageSubtractionCutouts.py script.
exported_csv_pth = 'exported_sources.csv'

def filter_data_by_ra_dec(data, min_ra, max_ra, min_dec, max_dec):
    """Filters data by the given RA and Dec range.
    """
    return data[(data['ra'] >= min_ra) & (data['ra'] <= max_ra) & (data['dec'] >= min_dec) & (data['dec'] <= max_dec)]

def match_catalogs(exported_cat, target_cat, threshold):
    """Matches two catalogs and returns indices and mask of matches within the threshold."""
    idx, d2d, _ = exported_cat.match_to_catalog_sky(target_cat)
    mask = d2d < threshold
    return idx, mask

def match_sources_in_space(exported_csv, filtered_sum, obj_type, threshold=1 * u.arcsec):
    """Matches sources in space and returns the matched sources with the object type."""
    exported_cat = SkyCoord(ra=exported_csv.ra, dec=exported_csv.dec, unit=u.deg)
    target_cat = SkyCoord(ra=filtered_sum.ra, dec=filtered_sum.dec, unit=u.deg)
    idx, mask = match_catalogs(exported_cat, target_cat, threshold)
    matched_sources = exported_csv.iloc[mask].copy()
    matched_sources['real'] = 1
    matched_sources['type'] = obj_type
    matched_sources['truth_id'] = filtered_sum.iloc[idx[mask]]["id"].values
    return matched_sources

def merge_and_update(df1, df2):
    """Merges two dataframes and updates the 'real' and 'type' columns."""
    combined = pd.merge(df1, df2[['diaSourceId', 'real', 'type','truth_id']], on='diaSourceId', how='left', suffixes=('', '_temp'))
    combined['real'] = combined['real_temp'].fillna(combined['real']).astype(int)
    combined['type'] = combined['type_temp'].fillna(combined['type'])
    combined.drop(columns=['real_temp', 'type_temp'], inplace=True)
    return combined

def combine_sources(exported_csv, matched_stars, matched_sn):
    """Combines the matched stars and supernovae with the exported sources."""
    exported_csv['real'] = 0
    exported_csv['type'] = None
    df_combined = merge_and_update(exported_csv, matched_stars)
    df_combined = merge_and_update(df_combined, matched_sn)
    return df_combined

def filter_by_mjd(df, min_mjd, max_mjd):
    """Filters variability data by the given MJD range."""
    return df[(df.MJD >= min_mjd) & (df.MJD <= max_mjd)].MJD.unique()

def match_mjd_sources(mjd_matched_in_space, unique_mjd_var, tolerance):
    """Matches MJD sources with given tolerance."""
    # return {mjd for mjd in mjd_matched_in_space if np.any(np.abs(unique_mjd_var - mjd) <= tolerance)}
    return {mjd for mjd in unique_mjd_var if np.abs(mjd_matched_in_space - mjd) <= tolerance}

def match_sources_in_time(df_combined, df_var, tolerance=0.00034):
    """Matches sources in time."""
    # mjd_matched_in_space = df_combined.midpointMjdTai.unique()
    matched_var = {}
    for index, row in tqdm(df_combined.iterrows(), total=df_combined.shape[0]):
        df_var_subset = df_var[df_var['id']==row['truth_id']]
        # matched_mjd = match_mjd_sources(row['midpointMjdTai'], df_var_subset['MJD'], tolerance)
        # matched_var[index] = df_var_subset[df_var_subset['MJD'] == matched_mjd]
        wmatch = df_var_subset['MJD'].apply(lambda x: np.abs(x - row['midpointMjdTai']) < tolerance)
        print(f"Matched {row['id']}")
        matched_var[index] = df_var_subset.loc[wmatch]
        print(df_var_subset.loc[wmatch])
        # if len(wmatch) > 0:
        #     print(wmatch.head())
        # print(len(matched_var))
        # if len(matched_var) == 1000:
        #     break
    df_matched_var = pd.DataFrame.from_dict(matched_var)
    # print(df_matched_var.head())
    df_matched_var.drop(columns=["MJD"], inplace=True)
    return df_combined.join(df_matched_var)
    # max_mjd, min_mjd = mjd_matched_in_space.max(), mjd_matched_in_space.min()
    # unique_mjd_var = filter_by_mjd(df_var, min_mjd, max_mjd)
    # return match_mjd_sources(mjd_matched_in_space, unique_mjd_var, tolerance)

def main():
    result_star_sum = pd.read_parquet(star_sum_path)
    result_sn_sum = pd.read_parquet(sn_sum_path)
    exported_csv = pd.read_csv(exported_csv_pth)
    
    min_exp_ra, max_exp_ra = exported_csv.ra.min(), exported_csv.ra.max()
    min_exp_dec, max_exp_dec = exported_csv.dec.min(), exported_csv.dec.max()

    filtered_star_sum = filter_data_by_ra_dec(result_star_sum, min_exp_ra, max_exp_ra, min_exp_dec, max_exp_dec)
    filtered_sn_sum = filter_data_by_ra_dec(result_sn_sum, min_exp_ra, max_exp_ra, min_exp_dec, max_exp_dec)

    matched_stars = match_sources_in_space(exported_csv, filtered_star_sum, "star")
    matched_sn = match_sources_in_space(exported_csv, filtered_sn_sum, "sn")

    df_combined = combine_sources(exported_csv, matched_stars, matched_sn)

    df_combined['truth_id'] = df_combined['truth_id_temp'].fillna(df_combined['truth_id'])
    df_combined['truth_id'] = df_combined['truth_id'].fillna(-1).astype(int)
    df_combined.drop(columns=['truth_id_temp'], inplace=True)

    print("Summary at the end of First Stage:")
    print(df_combined.groupby("real").count())

    df_matched = df_combined[df_combined["real"]==1]
    df_unmatched = df_combined[df_combined["real"]==0]

    df_star_var = pd.read_parquet(star_var_path)
    matched_star_mjd = match_sources_in_time(df_matched, df_star_var)
    df_sn_var = pd.read_parquet(sn_var_path)
    matched_sn_mjd = match_sources_in_time(df_matched, df_sn_var)

    matched_mjd = matched_star_mjd.union(matched_sn_mjd)
    df_matched['real'] = df_matched['midpointMjdTai'].isin(matched_mjd).astype(int)
    
    # df_matched.loc[df_matched['real']==0, 'type'] = None

    df_combined = pd.concat([df_unmatched, df_matched], ignore_index=True)
    print("Summary at the end of Second Stage:")
    print(df_combined.groupby("real").count())

    df_combined.to_csv("/sdf/home/h/harshit/public_html/sources_with_labels_2.csv", index=False)

if __name__ == "__main__":
    main()
